# Практики «Антиплагиат» и «Diff Tool»
Репозиторий содержит решения [этой](https://ulearn.me/course/basicprogramming2/Praktika_Antiplagiat__56409c8e-d038-45f7-8e37-e98c027b7930) и [этой](https://ulearn.me/course/basicprogramming2/Praktika_Diff_Tool__d71f996c-3bb0-4909-8c03-47322c4f0498) задачи с ulearn.me.
Задачи прошли код-ревью у преподавателя (баллы: 50/50, 100/100). Все решения курса на максимальный балл также выложены в других репозиториях.
Ветка unsolved содержит изначальный проект.

Конечное приложение - приложение для сравнения схожести документов. Как и серии предыдущих примеров, демонстрируется реализация алгоритмов.

## Практика «Антиплагиат»
ИТ-компания К. приглашает студентов на летнюю стажировку. Чтобы попасть на стажировку, претенденты решают тестовое задание — задачу на программирование вроде тех, что есть в этом курсе, только сложнее.

Из года в год претенденты присылают несколько сотен решений. Можно ли как-то автоматически найти среди них «списанные» решения, то есть такие, которые слишком сильно похожи друг на друга?

Оказывается расстояние Левенштейна можно использовать для того, чтобы сравнивать листинги программ (или вообще любые документы) друг с другом и находить самые похожие пары. Этим вам и предстоит заняться в данной задаче.

В этой задаче вам необходимо реализовать класс  `LevenshteinCalculator`, который получает на вход список документов и возвращает список попарных сравнений каждого документа с каждым другим.

Мы хотим, чтобы разница в пробелах, пустых строках или небольшом переименовании переменных не сбивала наш алгоритм. Поэтому вам нужно реализовать модифицированный алгоритм Левенштейна:

1.  Он должен анализировать не последовательности символов, а последовательности  **токенов**  — лексических единиц. Например, в коде  `force = mass * acceleration`  5 токенов:  `force`,  `=`,  `mass`,  `*`,  `acceleration`. Код разбиения на токены уже реализован и на вход вашему алгоритму поступает список токенов. Один документ представляется типом  `DocumentTokens`  (который объявлен, как синоним  `List<string>`).
    
2.  Если два токена различаются, то будем учитывать ещё степень различия. Стоимость замены одного токена на другой в алгоритме Левенштейна будем вычислять с помощью формулы коэффициента Жаккара. Она тоже реализована за вас в методе  `GetTokenDistance`  класса  `TokenDistanceCalculator`. Стоимость удаления/добавления токена равна единице, как и в оригинальном алгоритме.
    

Корректность работы проверяйте с помощью имеющихся в проекте модульных тестов.

## Практика «Diff Tool»
Алгоритм из предыдущей задачи находит похожие пары документов. В этой задаче вам предстоит проанализировать два документа и найти в них повторяющиеся части. Подобную задачу решают так называемые Diff Tools — инструменты для сравнения текстовых файлов.

Для этого вам нужен алгоритм, который будет по двум последовательностям токенов возвращать их наибольшую общую подпоследовательность. Она должна состоять из токенов первой последовательности, которые в том же порядке присутствуют и во второй последовательности (токены не обязательно должны идти подряд). И из всех таких последовательностей вернуть нужно самую длинную. Если самых длинных несколько, можно вернуть любую.

Например, у документов  `a1 b2 ab1 b21 b2`  и  `b2 b2 a1`  (токены разделены пробелом) наибольшая общая подпоследовательность — это  `b2 b2`  и имеет длину 2 токена.

Реализуйте это в методе  `Calculate`  в классе  `LongestCommonSubsequenceCalculator`  и отладьте реализацию на тестах  `LongestCommonSubsequenceCalculator_Tests`. Как и в прошлой задаче документы приходят в ваш метод уже разбитые на токены, вам этого делать не нужно.

### Подсказки по алгоритму

Поиск длины наибольшей общей подпоследовательности — ещё одна классическая задача динамического программирования. Она решается, как и расстояние Левенштейна, с помощью построчного заполнения двумерного массива, назовём его  `opt`, с таким инвариантом:

`opt[i1, i2]`  — это длина наибольшей общей подпоследовательности префикса первого документа длины  `i1`  и префикса второго документа длины  `i2`.

В частности  `opt[0, 0] = 0`  (оба префикса пустые). А  `opt[first.Length, second.Length]`  — это длина искомой подпоследовательности для документов  `first`  и  `second`. Начните с того, что напишите формулу для расчёта значения очередной ячейки  `opt[i1, i2]`  через уже известные ячейки  `opt`.

Саму подпоследовательность можно найти по заполненной матрице, начав с  `opt[first.Length, second.Length]`.

### Запуск проекта

В папке  `SuspiciousSources`  лежат документы, которые нужно проверить на плагиат. После того, как вы отладите ваше решение на тестах, запустите проект на исполнение. На консоль выведется расстояние Левенштейна между каждой парой документов, а в директории с exe-файлом появится html-файл с отчётом, где у двух решений будет выделена общая часть. Откройте этот отчёт в браузере и изучите результат!

### Обсуждение скорости работы алгоритмов

Оба алгоритма из этой серии задач имеют квадратичную сложность относительно размера документа. Кроме того, для сравнение каждого документа с каждым — тоже квадратичная операция относительно количества документов. Из-за этого, как вы могли заметить, поиск похожих пар документов работает не особенно быстро. А значит для анализа тысяч решений, размером в килобайт, нужно искать другой более быстрый алгоритм.
